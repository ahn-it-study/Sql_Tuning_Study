# 인덱스 튜닝
### 파티션 프루닝?
> 하드 파싱이나 실행 시점에서 SQL 조건절을 분성하여 읽지 않아도 되는 파티션 세그먼트를 액세스 대상에서 제외시키는 기능??  
> 샤딩??
# 인덱스 ROWID는 물리적 주소인가 논리적 주소인가?
## ROWID의 구성요소
- 데이터파일 번호
- 오브젝트 번호
- 블록 번호

## 인덱스를 스캔하는 이유
- 검색 조건을 만족하는 소량의 데이터를 인덱스에서 빨리 찾고 거기서 테이블 레코드를 찾아가기 위한 ROWID를 얻으려는데 있다.  
## 그래서?
-> 물리적으로 직접 연결되는것이 아닌 테이블 레코드를 찾아가기위한 논리적 주소 정보를 가지고 있기 때문이다.
-> 인덱스 ROWID는 논리적 주소이고 디스크 상에서 테이블 레코드를 찾아가기 위한 위치 정보를 담는다. (물리적으로 직접 연결되어있는 구조가 아님.)
-> 그래서 ROWID는 물리적 주소보다 논리적 주소에 가깝다.

# 메인 메모리 DB와의 비교
## Main Memory Database? (REDIS? Memcached?)
- 데이터를 모두 메인메모리에 올려놓고 메인 메모리를 통해서만 I/O를 수행하는 DB  
잘 튜닝된 [OLTP](https://mozi.tistory.com/80) 데이터베이스 시스템이라면 버퍼캐시 히트율이 99% 이상이다.  
그런데도 메인 메모리 데이터베이스보다 빠르지 않다. 특히 대용량 데이터를 인덱스로 액세스 할 때에는 엄청난 차이가난다.   
## Main Memory Database가 더 빠를 수 밖에 없는 이유
- 어떤 메인 메모리 DB의 경우 인스턴스를 기동하면 디스크에 저장된 데이터를 버퍼캐시로 로딩하고 이어서 인덱스를 생성한다.   
- 디스크상의 주소정보를 가지는게 아니다. 실제 메인 메모리 상의 주소정보를 가진다.  
-> 인덱스를 경유해 액세스 하는 비용이 오라클과 비교도 할 수 없을정도로 낮음  
-> 일반 DBMS에서 인덱스 ROWID를 이용한 테이블 액세스가 생각만큼 빠르지 않은 이유임.  

## I/O 메커니즘 복기
### 버퍼 캐시
- DBA(Data Block Address)를 읽으려면 매번 디스크상에서 불러올 순 없다.  
- I/O성능을 높이려면 버퍼 캐시를 활용해야한다.  
- 그래서 블록을 읽을 땐 디스크로 가기전에 버퍼캐시를 먼저 찾아본다.  
- 읽고자 하는 DBA를 해시 함수에 넣어서 해시 체인을 찾고 거기에서 버퍼 헤더를 찾는다.  
- 반면 실제 데이터가 담긴 버퍼 블록은 매번 다른 위치에 캐싱이 되는데 그 주소값을 버퍼 헤더가 가지고 있다.  
### 버퍼 캐시 탐색과정
1. 해시 알고리즘으로 버퍼 헤더를 찾는다 (Input은 DBA)  
2. 거기서 얻은 주소값으로 버퍼 블록을 찾아간다.  
### 하지만
인덱스 리프 블록에 있는 ROWID를 취득했다하더라도 버퍼캐시 탐색은 무조건 일어나게된다.  
그런데 버퍼캐시는 공유자원이다. 그렇기 때문에 동시 액세스가 심할 땐 캐시버퍼 체인 래치와 버퍼 Lock에 대한 경합까지 발생한다.  
이처럼 인덱스 ROWID를 이용한 테이블 액세스는 생각보다 고비용 구조다.  
## 인덱스 ROWID는 우편주소
- DISK DB(일반 DBMS)가 사용하는 ROWID를 우편주소에 비유
- 메인 메모리 DB가 사용하는 포인터를 전화번호에 비유
> 전화통신은 물리적으로 연결된 통신망을 이용하므로 전화번호를 누르면 바로 상대방과 통화할 수 있다.  
> 우편통신은 봉투에 적힌대로 우체부 아저씨가 찾아다니는 구조이므로 전화와는 비교도 할 수 없이 느리다.  

-> 책에서 강조하는 것은 인덱스를 통해 테이블을 찾아가는게 얼마나 큰 비용의 작업인지 상기시켜주려는것 같음  
-> 인덱스가 무조건적으로 빠르다고 생각하면 안된다.  
# Clustering Factor
> 특정 컬럼을 기준으로 같은 값을 갖는 데이터가 서로 모여있는 정도   
예를들어 거주지역 = 제주에 해당하는 고객이 물리적으로 근접해있다면 흩어져 있을 때 보다 데이터를 찾는 속도가 빠르다.  
또 한가지 더 들어보자면 분가한 10명의 자녀들이 한 동네에 살고있다면 부모 있장에서는 클러스터린 팩터가 좋은것이다.  
한 동네만 돌면 자녀들의 집을 다 방문할 수 있기 때문이다.  
![클러스터링 팩터가 좋은상태](https://user-images.githubusercontent.com/23313008/165489339-4b2ba317-f876-4b2d-98a5-220823bc35b7.png)  
(클러스터링 팩터가 좋은 경우.png)  
> 테이블 액세스량에 비해 블록 I/O가 적게 발생함
### Clustering Factor가 좋지 않은 경우
![notgood](https://user-images.githubusercontent.com/23313008/165489799-a5c3e6ea-71ca-4b26-9ffb-7b9fe25ebbc1.png)  
(클러스터링 팩터가 좋지 않은 경우.png)  
인덱스 레코드 정렬순서와 테이블 레코드 정렬 순서가 전혀 일치하지 않는다.  
## 인덱스 손익분기점
- 인덱스 ROWID를 이용하는것은 생각보다 고비용 구조이다.  
- 읽어야할 데이터가 일정량을 넘는 순간 테이블 전체를 스캔하는 것보다 오히려 느림  
- Index Range Scan에 의한 테이블 액세스가 Table Full Scan보다 느려지는 지점을 흔히 인덱스 손익 분기점이라고 부른다.  
## 인덱스를 이용한 테이블 액세스가 Table Full Scan보다 느려지는 핵심요인
- Table Full Scan은 시퀀셜 액세스인 반면 인덱스 ROWID를 이용한 테이블 액세스는 랜덤 액세스 방식
- Table Full Scan은 Multiblock I/O인 반면 인덱스 ROWID를 이용한 테이블 액세스는 Single Block I/O  방식
> CF가 안좋으면 데이터 블록을 여러번 반복 액세스 하면서 물리적, 논리적 I/O 횟수가 늘어난다.  
## 인덱스 손익분기점 결정
- CF가 나쁠 경우 -> 5% 미만에서 결정
- 일반적으로 -> 5%-20%사이
- CF가 좋으면 -> 90% 수준까지 상승
여기서 말하는 %는 테이블 데이터 갯수기준이다.  
### 인덱스 손익분기점과 버퍼캐시 히트율
일반적으로 말하는 5%-20% 수준의 손익분기점은 10만건 이내, 많아봐야 100만건 이내 테이블에나 적용되는 수치이다.  
1000만건 수준의 큰 테이블에선 손익분기점이 더 낮아진다. 
왜냐하면 조회건수가 늘어날수록 버퍼캐시에서 찾을 '가능성'이 낮아지기 떄문이다.  
버퍼캐시에 할당하는 메모리 크기가 점점 늘어나고있는 추세이지만 요즘 기준으로 보통 수백만개 블록을 캐싱하는 수준이기 떄문이다.    
-> 만약 100만개의 데이터가 있는 테이블의 10%는 10만개이다. 이 정도 수준이면 버퍼캐시에서 데이터를 찾을 가능성은 꽤 높다.  
-> 만약 1000만개의 데이터가 있는 테이블이라면 100만개가 되는거고 즉 히트율을 점점 낮아질 수 밖에 없다.  
### 책에서 말하고 싶어하는 바
- 인덱스는 항상 좋은게 아니고 테이블 스캔이 항상 나쁜게 아니다.
## 온라인 프로그램 튜닝 vs 배치 프로그램 튜닝
### 온라인 프로그램
- 온라인 프로그램은 대개 소량의 데이터를 읽고 갱신하므로 인덱스를 효과적으로 활용하는 것이 무엇보다 중요하다.  
- 조인도 대부분 NL방식을 이용함  
- 인덱스를 이용해 소트 연산을 생략함으로써 2절에서 설명할 부분범위처리 방식으로 구현할 수 있다면, 온라인 환경에서 대량의 데이터를 조회할 때도 빠른 응답성을 보여줄 수 있음.  
### 배치 프로그램
- 배치 프로그램의 특성은 대량의 데이터를 조회하고 처리함  
- 그렇기 떄문에 전체를 빠르게 처리하는것을 목표로 삼아야함
- 대량의 데이터를 빠르게 처리하려면 인덱스와 NL 조인보다 Full Scan과 해시 조인이 유리하다.  
- 대량 배치 프로그램에선 인덱스보다 Full Scan이 효과적이지만 초대용량 테이블을 Full Scan하면 시스템에 부담이 상당하다.
- 따라서 대용량 배치 프로그램에서 중요한 튜닝 포인트는 파티션 활용 전략이 매우 중요한 튜닝요소이고 병렬처리까지 더할 수 있으면 금상천화이다.
### 대용량 배치 프로그램을 파티션을 활용하여 튜닝
고객이력변경 테이블  
- 고객번호, 고객명, 전화번호, 주소, 상태코드, 변경일시  
- **변경일시 조건으로 검색**
위 테이블에서 변경일시 기준으로 파티셔닝하면 변경일시 조건에만 해당하는 파티션을 골라서 Full Scan할 수 있다.   
- 보름 또는 일주일치 데이터만 조회하더라도 Full Scan이 유리함.  
- 심지어 2~3일 데이터를 조회할 때도 Full Scan이 유리할 수 있다.  
### 결국 테이블을 파티셔닝 하는 이유는
- Full Scan을 빠르게 처리하기 위해서다.  
> 다시 강조한다. 모든 성능 문제를 인덱스로 해결하려 해선 안된다. 인덱스는 다양한 튜닝 도구중 하나일 뿐이며 큰 테이블에서 아주 작인 일부 데이터를 빨리 찾고자 할 때 주로 사용한다.  
## 인덱스 컬럼 추가
- 테이블 액세스 최소화를 위해 가장 일반적으로 사용하는 기법은 인덱스에 컬럼을 추가하는 것이다.  
인덱스 구성을 실제 라이브되고있는 제품에서 변경하기란 쉽지 않다.  
또한 인덱스를 한개씩 추가하다보면 테이블마다 인덱스가 수십개씩 달려 배보다 배꼽이 더 커지는 경우가 발생한다.  
인덱스 관리 비용이 증가함은 물론 DML 부하에 따른 트랜잭션 성능 저하가 발생할 수 있다.  
## 인덱스만 읽고 처리
- 테이블 랜덤 액세스가 아무리 많아도 필터 조건에 의해 버려지는 레코드가 거의 없다면 거기에 비효율은 없다.  
- 이런 경우에는 어떻게 튜닝해야할까?  
### Covered Query & Covered Index
- 쿼리에 사용된 컬럼을 모두 인덱스에 추가해서 테이블 액세스가 아예 발생하지 않도록 하는 방법이 있다.  
- 인덱스만 읽어서 처리하는 쿼리를 Covered Query라고 부르며 그 쿼리에 사용한 인덱스를 Covered Index라고 부른다.  
- 이 방법은 효과가 매우 좋지만 추가해야할 컬림이 많아 실제 적용하기 곤란한 경우도 많다.  
## Index 구조 테이블
- 인덱스를 이용한 테이블 액세스가 고비용 구조라고 하니 랜덤 액세스가 아예 발생하지 않도록 테이블을 인덱스 구조로 생성하면 어떨까?  
- 오라클에 존재함  
- 테이블을 찾아가기 위한 ROWID를 갖는 일반 인덱스와 달리 IOT는 그 자리에 테이블 데이터를 갖는다.  
- 즉, 테이블 블록에 있어야 할 데이터를 인덱스 리프 블록에 모두 저장하고 있는다.  
- 일반 테이블 형식은 힙 구조 테이블이라고 부른다.  
- 일반 힙 구조 테이블 형식은 입력할 때 랜덤 방식으로 입력된다.  
- 즉 Freelist로부터 할당받은 블록에 정해진 순서 없이 데이터를 입력한다.  
- 반면 IOT는 인덱스 구조 테이블이므로 입력될 때 정렬 상태를 유지하며 입력된다.  
- IOT는 인위적으로 클러스터링 팩터를 좋기 만드는 방법중 하나  
- 같은 값을 가진 레코드들이 100%로 정렬되어있기 때문에 랜덤 액세스가 아닌 시퀀셜 방식으로 데이터를 액세스한다.
## 클러스터 테이블
- 인덱스 클러스터  
- 해시 클러스터 테이블
### 인덱스 클러스터 테이블
![인덱스클러스터테이블](https://user-images.githubusercontent.com/23313008/165776774-849f469b-5e50-4dba-b83a-3c935fd8e192.png)  
- 인덱스 클러스터 테이블은 위 그림과 같이 클러스터 키 (deptno)값이 같은 레코드를 한 블록에 모아서 구조.  
- 한 블록에 모두 담을 수 없을 때는 새로운 블록을 할당하여 클러스터 체인으로 연결한다.  
- 일반 테이블에 생성한 인덱스는 테이블과 1:1 관계를 갖지만 클러스터 인덱스는 1:n을 가진다.  
- 따라서 클러스터 인덱스의 키값은 항상 유니크하다.  
이러한 구조적 특성 덕분에 클러스터 인덱스를 스캔하면서 값을 찾을 때는 랜덤 액세스가 값 하나당 한번씩 밖에 발생하지 않는다.  
클러스터에 도달한 이후부터는 시퀀셜 방식으로 스캔하기때문에 넓은 범위를 읽더라도 비효율이 없다는 게 핵심원리다.  
### 해시 클러스터 테이블
![해시클러스터ㅡ png](https://user-images.githubusercontent.com/23313008/165777873-4c4e2323-e3e5-402e-a340-bfaa97c7f2c9.png)  
- 해시 클러스터는 인덱스를 사용하지 않고 해시 알고리즘으로 찾아간다.  
# 부분처리 범위 활용
> 테이블 랜덤 액세스로 인한 인덱스 손익분기점의 한계를 극복할 히든카드를 추가로 소개한다.  
> 부분범위 처리 원리가 바로 그것인데 이를 활용하면 인덱스로 액세스 할 대상 레코드가 아무리 많아도 아주 빠른 응답속도를 낼 수 있다.  
## 부분 범위 처리
DBMS가 클라이언트에게 데이터를 전송할 때도 일정량씩 나누어 전송한다.  
전체 결과집합중 아직 전송하지 않은 분량이 많이 남아있어도 서버 프로세스는 클라이언트로부터 추가 Fetch Call을 받기 전까지 그대로 멈춰 서서 기다린다.  
```java
private void execute(Connection connection) throw Exception {
    Statement stmt = connection.createStatement();
    ResultSet rs = stmt.executeQuery("select name from big_table");

    for(int i = 0; i < 100; i++){
        if(rs.next()) {
            System.out.println(rs.getString(1));
        }
    }

    rs.close();
    stmt.close();
}
```
OLTP 환경에서 대용량 데이터를 빠르게 핸들링할 수 있는 아주 중요한 원리가 바로 여기에 있다.  
예를들어 마우스 클릭시 위 Java 메소드를 호출하는 실행 버튼이 있다고 치자.  
SQL문에 사용한 BIG_TABLE이 1억건에 이르는 대용량 테이블이어도 실행결과는 클릭하자마자 곧바로 화면에 출력된다.  
이유는 DBMS가 데이터를 모두 읽어 한번에 전송하지 않고 먼저 읽는 데이터부터 일정량을 전송하고 멈추기 떄문이다.  
데이터를 전송하고 나면 서버 프로세스는 CPU를 OS에 반환하고 대기 큐에서 잠을 잔다.  
다음 Fetch Call을 받으면 대기 큐에서 깨어나 다음 데이터를 일정량 읽어온다.  
### Fetch Call 순서
1. 최초 rs.next() 호출 시 Fetch Call을 통홰 DB서버로부터 전송받은 데이터를 클라이언트 캐시에 저장한디.
2. 이후 rs.next() 호출할 때는 Fetch Call을 발생시키지 않고 캐시에서 데이터를 읽어온다.
3. 캐시에 저장한 데이터를 모두 소진한 상태에서 rs.next()호출 시 추가 Fetch Call을 통해 10건을 전송받는다.
4. 100건을 다 읽을 때 까지 2~3번 과정을 반복한다.
### Fetch Call?
> 부분 범위 처리의 경우 데이터를 일정량씩 나누어서 전송하기때문에 클라이언트가 DBMS에게 데이터를 더 달라고 하는 요청  
## 정렬 조건이 있을 때 부분범위 처리
DB서버는 모든 데이터를 다 읽어 순서대로 정렬을 다 마치고나서야 클라이언트에게 전송을 시작할 수 있다.  
전체범위 처리이다.  
Sort Area와 Temp 테이블 스페이스까지 이용해 데이터 정렬을 마치고 나면 그때부터 일정량씩 나눠 클라이언트에게 데이터 전송을 시작한다.  
하지만 선두 컬럼인 인덱스가 있으면 부분 범위 처리가 가능해진다.(인덱스가 항상 정렬된 상태로 유지되기 때문)  
## Array Size 조정을 통한 Fetch Call 최소화
부분범위 처리의 원리를 이해했다면 네트워크를 통해 전송해야 할 데이터량에 따라 Array Size를 조절할 필요가 있음을 직감했을 것이다.  
예를들어 대량 데이터를 파일로 내려받는다면 어차피 데이터를 모두 전송해야 하므로 가급적 그 값을 크게 설정해야한다.  
Array Size를 조정한다고 해서 전송해야할 데이터의 총량은 변하지 않지만 Fetch Call 횟수를 줄일 수 있다.  
반대로 앞쪽 일부 데이터만 Fetch하다가 멈추는 프로그램이라면 Array Size를 작게 설정하는것이 유리하다.  
## OLTP 환경에서의 부분범위 처리에 의한 성능개선 원리
보통 OLTP 환경에서는 소량의 데이터를 빠르게 읽고 처리하는게 포인트다.  
하지만 대량의 데이터를 조회해야하는 경우가 있다.  
이때 인덱스와 부분 범위 처리 원리를 잘 활용한다면 OLTP환경에서 극적인 성능개선을 보여줄 수 있다.  
그럴때 항상 정렬상태를 유지하는 인덱스를 이용하면 정렬 작업을 생략하고 앞쪽 일부 데이터를 아주 빠르게 보여줄 수 있다.  
## 멈출 수 있어야 의미있는 부분범위처리
문제는 앞쪽 일부만 출력하고 멈출 수 있는가이다.  
클라이언트 프로그램이 DB서버에 직접 접속하는 2-Tier 환경에서는 그렇게 구현할 수 있었고 실제로도 그렇게 많이 구현했다.  
하지만 클라이언트와 DB서버 사이에 WAS, AP 서버등이 존재하는 n-Tier 아키텍처에서는 클라이언트가 특정 DB 커넥션을 독점할 수 없다.  
단위 작업을 마치면 DB 커넥션을 곧바로 커넥션 풀에 반환해야 하므로 그 전에 SQL 조회 결과를 클라이언트에게 모두 전송하고 커서를 닫아야한다.  
# 인덱스 스캔 효율화
## 인덱스 스캔 효율성
![예시문자열테이블](https://user-images.githubusercontent.com/23313008/165897851-2b3009dc-d660-4122-8254-6e34298ea189.png)  
### 질문 1
위 그림에서 '성능검'으로 시작하는 용어를 검색하고자 할 때 어디서 스캔을 시작하고 어디서 멈출까?  
> '성능검사'에서 스캔을 시작한다. 가나다 순으로 정렬돼있으므로 끝까지 안 읽고 멈출 수도 있다. '성능계수'인 지점에서 멈추면된다.  
> '성능검'으로 시작하는 용어가 더 없을을 확인하려니 '성능계수'까지 읽은것이다.  
### 질문 2
이번에는 '성능'으로 시작하고 네 번째 문자가 '선'인 용어를 검색해보자. 어디서 스캔을 시작하고 멈출까?  
> '성능'으로 시작하는 용어를 모두 스캔한다. 결과는 똑같이 두건이지만 좌측 그림보다 훨씬 더 많은 용어를 스캔해야한다.  
![indexedstringtables](https://user-images.githubusercontent.com/23313008/165898449-7ac19031-79c9-454c-913c-c879d84f67d2.png)  
이번엔 문자열 한 글자마다 인덱스를 지정한다.  
### 질문 3
이 테이블에서 '성능검'으로 시작하는 레코드를 검색하려면 아래와 같은 조건절을 사용한다.  
이 조건절에 위 그림의 인덱스를 사용한다면 어디서 스캔을 시작하고 멈출까?  
```sql
WHERE c1 = '성' AND c2 = '능' AND c3 = '검'
```

-> '성능검'으로 시작하는 레코드를 검색할 때는 인덱스를 수직적 탐색을 통해 '성능검사'레코드로 찾아간다.  
거기서 스캔을 시작해 '성능계수' 까지 총 세 개 레코드를 스캔하고 멈춘다.  
두 건을 얻기 위해 세 건을 스캔했다.  
### 질문 4
'성능'으로 시작하고 네 번째 컬럼이 '선'인 레코드를 검색하려면 아래와 같은 조건절을 사용한다.  
위 그림의 인덱스를 사용한다면 어디서 스캔을 시작하고 멈출까?
```sql
WHERE c1 = '성' AND c2 = '능' AND c4 = '선'
```

-> '성능'으로 시작하고 네 번째 컬럼이 '선'인 레코드를 검색할 때는 '성능'으로 시작하는 레코드를 모두 스캔한다.  
질문3보다 훨씬 더 많은 인덱스 레코드를 스캔해야한다.  
왜 효율성에 차이가 나는 걸까?  
왜냐하면 인덱스 선행 컬럼이 조건절에 없기 때문이다. 위 그림의 인덱스로 말하면 C4보다 앞선 선행 컬럼 C3가 조건절에 없기떄문이다.  
인덱스 선행 컬럼이 조건절에 없거나 '='조건이 아니면 인덱스 스캔 과정에 비효율이 발생한다.  
## 액세스 조건과 필터 조건
- 인덱스를 스캔하는 단계에 처리하는 조건절은 액세스 조건과 필터 조건으로 나뉜다.  
### 인덱스 액세스 조건
- 인덱스 액세스 조건은 인덱스를 스캔하는 범위를 결정하는 조건절이다.  
- 인덱스 수직적 탬색을 통해 **스캔 시작점**을 결정하는데 영향을 미치는 조건절이다.  
### 인덱스 필터 조건 (이부분 약간 이해 안됨...)
- 테이블로 액세스 할지 결정하는 조건절이다.  
![indexedstringtables](https://user-images.githubusercontent.com/23313008/165898449-7ac19031-79c9-454c-913c-c879d84f67d2.png)  
질문 3 쿼리의 경우 C1,C2,C3가 모두 인덱스 액세스 조건이었다.  
질문 4 쿼리의 경우 C1, C2가 인덱스 액세스 조건이었고 C4가 인덱스 필터 조건이었다.  
> 인덱스를 이용하든 테이블을 Full Scan하든 테이블 액세스 단계에서 처리되는 조건절은 모두 필터 조건이다.  
### 테이블 필터조건
- 쿼리 수행 다음 단계로 전달하거나 최종 결과 집합에 포함할지를 결정한다.
## 비교 연산자 종류와 컬럼 순서에 따른 군집성
테이블과 달리 인덱스에는 '같은 값'을 갖는 레코드들이 서로 군집해있다. '같은 값'을 찾을 때 '=' 연산자를 사용하므로  
인덱스 컬럼을 앞쪽부터 누락없이 '='연산자로 조회하면 조건을 만족하는 레코드는 모두 모여있다.  
```sql
WHERE c1=1 AND c2=1 AND c3=1 AND c4=1
```
어느 하나를 누락하거나 '='조건이 아닌 연산자로 조회하면 조건절을 만족하는 레코드가 서로 흩어진 상태가된다.  
### 조건절 1
```sql
WHERE c1=1 AND c2=1 AND c3=1 AND c4=1
```
위 조건절과 같이 인덱스 구성컬럼을 모두 '='조건으로 비교할 때는 조건을 만족하는 레코드들이 모두 연속해서 모여있다.  
### 조건절 2
```sql
WHERE c1=1 AND c2=1 AND c3=1 AND c4 >= 1
```
선행컬럼은 모두 '='이고 맨 마지막 컬럼만 범위조건 일떄도 조건을 만족하는 레코드가 서로 모여있다.  
### 조건절 3
```sql
WHERE c1=1 AND c2=1 AND c3 between '가' AND '다' AND c4=1
```
위와같이 C3이 범위조건 일 경우 C1, C2, C3은 모여있지만 C4는 흩어지게 된다.  

> 선행 컬럼이 모두 '='조건인 상태에서 첫 번째 나타나는 범위검색 조건까지만 만족하는 인덱스 레코드는 모두 연속해서 모여있지만
> 그 이하 조건까지 만족하는 레코드는 비교 연산자 종류에 상관없이 흩어진다.  
```sql
WHERE c1 between 1 and 3 AND c2=1 AND c3=1 AND c4=1
```
위 처럼 가장 선두 컬럼이 범위검색 조건이면 그 조건이 스캔 범위를 결정한다.  
따라서 이들 조건이 인덱스 액세스 조건이고 나머지 컬럼은 모두 인덱스 필터 조건이다.  
## 인덱스 선행 선두 컬럼이 등치(=)조건이 아닐 때 발생하는 비효율
- 인덱스 스캔 효율성은 인덱스 컬럼을 조건절에 모두 등치 조건으로 사용할 때 가장 효율이 좋다.
- 리프 블록을 스캔하면서 읽은 레코드는 하나도 걸러지지 않고 테이블 액세스로 이어지므로 인덱스 스캔 단계에서의 비효율은 전혀 없다.  
- 인덱스 컬럼 중 일부가 조건절에 없거나 등치 조건이 아니더라도 그것이 뒤쪽 컬럼일땐 비효율이 없다.  
- 반면 인덱스 선행 컬럼이 조건절에 없거나 부등호, BETWEEN, LIKE같은 범위검색 조건이면 인덱스를 스캔하는 단계에서 비효율이 생긴다.  
## BETWEEN을 IN-LIST로 전환
![betweeninlist drawio](https://user-images.githubusercontent.com/23313008/165906803-aedef65d-d390-4470-bf38-75b3dacec555.png)  
- 운영시스템에선 인덱스 구성을 바꾸기는 쉽지 않다.  
- 이럴 때 BETWEEN 조건을 아래와 같이 IN-List로 바꿔주면 큰 효과를 얻는 경우가 있다.
```sql
SELECT * FROM WHERE 인터넷매물 in ('1', '2', '3');
```
위 그림은 BETWEEN 조건을 IN-List로 바꾸었을 때 스캔과정을 도식화 한것이다.  
화살표가 세개인 이유는 인덱스 수직적 탐색이 세 번 발생하기 때문이다.  
하지만 IN-List 항목 개수가 늘어날 수 있다면 이 방식은 사용하기 곤란하다.  
그럴때는 NL방식의 조인문이나 서브쿼리로 구현하면 된다.  
### BETWEEN 조건을 IN-List로 전환할 때 주의 사항
- IN-List 개수가 많으면 수직적 탐생이 많이 발생한다.  
- 그러면 BETWEEN 조건 때문에 리프 블록을 많이 스캔하는 비효율보다 IN-List 개수만큼 브랜치 블록을 반복 탐색하는 비효율이 더 클 수있다.
- 조건은 만족하는 레코드가 멀리 떨어져 있을 때만 유용하다.
## Index Skip Scan 활용
- BETWEEN 조건을 IN-List로 바꾸면 도움이 되는 상황에서 굳이 조건절을 바꾸지 않고도 같은 효과를 낼 수 있는 방법이 있다.  
- Index Skip Scan을 활용하는 것이다.  
- 선두컬럼이 BETWEEN 이어서 나머지 검색 조건을 만족하는 데이터들이 서로 멀리 떨어져 있을 때 Index Skip Scan의 위력이 나타난다.  
### IN 조건은 '=' 인가?
- SQL 튜닝 입문자에게서 흔히 볼 수 있는 현상은 IN 조건을 '='조건과 동등시한다는 점이다.  
고객별가입상품 테이블에서 고객번호의 평균 카디널리티는 3이라고 가정하자.  
즉 고객별로 평균 세 건의 상품에 가입한다.  
인덱스를 상품ID + 고객번호 순으로 생성하면 같은 상품은 고객번호 순으로 정렬된 상태로 하나 또는 연속된 두개의 리프 블록에 저장된다.  
반면, 고객번호 기준으로는 같은 고객번호가 상품 ID에 따라 뿔뿔이 흩어진 상태가 된다.  
이런경우 상품 ID 조건절이 IN-List-Iterator 방식으로 풀리는것이 효과적이다.  
고객번호 = 1234를 만족하는 레코드가 서로 멀리 떨어져 있기 떄문이다.  
이 인덱스 구성에서는 상품 ID 조건절이 IN-List Iterator 방식으로 풀려야한다.  
인덱스를 정상적으로 사용하려면 수직적 탐색을 통해 스캔 시작점을 찾아야하는데 상품 ID가 NH0037 이거나 NH0041이거나 NH0050인 어느 한 지점을  
바로 찾을 수 없기 때문이다.  
이 경우 IN-List Iterator로 풀지 않으면 인덱스 전체를 스캔하면서 필터링 해야한다.  
## BETWEEN과 LIKE 스캔 범위 비교
BETWEEN, LIKE는 둘 다 범위검색 조건으로서, 앞에서 설명한 범위조건을 사용할 때 발생하는 비효율 원리가 똑같이 적용된다.  
LIKE 보다 BETWEEN을 사용하는게 낫다.  
### 예시
인덱스를 판매월 + 판매구분 순으로 구성했다.  
판매 구분으로는 'A', 'B'가 존재하고 각각 90%와 10%의 비중을 차지하는 상황에서 아래 두 조건절에 대해 인덱스 스캔량을 비교해보자.  
### 조건절 1
```sql
where 판매월 BETWEEN '201901' and '201912' and 판매구분 = 'B'
```
### 조건절 2
```sql
where 판매월 LIKE '2019%' and 판매구분 = 'B'
```

조건절 1은 판매월 '201901'이고 판매구분 'B'인 첫 번째 레코드에서 스캔을 시작한다.  
반면 조건절 2는 판매월 '201901'인 첫 번째 레코드에서 스캔을 시작한다.  
혹시라도 '201900'이 저장돼있다면 그 값도 읽어야 하므로 판매구분 'B'인 지점으로 바로 내려갈 수 없다.  
## 범위검색 조건을 남용할 때 생기는 비효율
LIKE로 검색을 하는 컬럼이 Index일 경우 주의해야한다.  
어떤 인덱스 컬럼에 LIKE를 사용하는 경우 스캔범위가 늘어나는데 액세스 조건이 필터 조건으로 바뀌기 때문이다.  
## 다양한 옵션 조건 처리 방식의 장단점 비교
### OR 조건 활용
- 옵티마이저에 의한 OR Expression 쿼리 변환이 기본적으로 작동하지 않는다.  
- 따라서 인덱스 선두 컬럼에 대한 옵션 조건에 OR 조건을 사용해선 안된다.  
- 인덱스에 포함되지 않은 컬럼에 대한 옵션 조건은 어차피 테이블에서 필터링 할 수 밖에 없으므로 OR을 사용해도 무방하다.  
1. 인덱스 액세스 조건으로 사용불가
2. 인덱스 필터 조건으로도 사용불가
3. 테이블 필터 조건으로만 사용가능 
- OR 조건을 이용한 옵션 처리는 가급적 사용하지 말아야함.  
- 이 방식의 유일한 장점은 옵션 조건 컬럼이 NULL허용 컬럼이더라도 결과집합을 보장한다는 것 뿐이다.
### LIKE/BETWEEN 조건 활용
- 변별력이 좋은 필수 조건이 있는 상황에서 이들 패턴을 사용하는것은 나쁘지 않다.
- 필수 조건 컬럼을 인덱스 선두에 두고 액세스 조건으로 사용하면, LIKE/BETWEEN이 인덱스 필터 조건이어도 충분히 좋은 성능을 낼 수 있기 때문이다.  
```sql
WHERE 등록일시 >= trunc(sysdate) -- 필수조건 (당일등록상품)
AND 상품분류코드 like :prd_cls_cd || '%' -- 옵션 조건
```
더욱이 필수 조건이 등치비교 '='이면 더 좋은 효율을 낼 수 있다.  
문제는 필수 조건의 변별력이 좋지 못할때다.  
예를들어 상품대분류코드만으로 조회할 때는 Table Full Scan이 유리하다.  
그런데 옵티마이저는 상품 코드를 입력할 대를 기준으로 Index Range Scan을 선택한다.  
다행이 사용자가 상품 코드를 입력하면 최적의 성능을 내겠지만 그렇지 않을 때 문제가 생긴다.  
이외에도 LIKE/BETWEEN 패턴을 사용하고자 할 떄는 아래 네 가지 경우에 속하는지 확인해봐야한다.  
(between은 1,2번만 고려하면 된다.)
1. 인덱스 선두 컬럼
2. NULL 허용 컬럼
3. 숫자형 컬럼
4. 가변 길이 컬럼
### 1. 인덱스 선두 컬럼에 대한 옵션 조건을 LIKE/BETWEEN 연산자로 처리하는것은 금물이다.
- 예를들어 인덱스를 고객ID + 거래 일자로 구성한 상황에서 고객 ID에 대한 옵션 조건을 LIKE로 처리했다고 하자.
```sql
SELECT * FROM 거래 WHERE 고객ID like :cust_id || '%' AND 거래일자 between :dt1 and :dt2
```

사용자가 고객 ID를 입력하면 둘다 범위검색 조건이어서 인덱스 스캔 과장에서 약간 비효율이 있더라도 고객ID가 변별력이 매우 좋기 떄문에  
비교적 빠르게 조회된다.  
만약 사용자가 고객 ID를 입력하지않으면 인덱스에서 '모든'거래 데이터를 스캔하면서 거래 일자 조건을 필터링 하는 불상사가 발생한다.  
### 2. NULL허용 컬럼에 대한 옵션 조건을 LIKE/BETWEEN 연산자로 처리하는 것도 금물이다.
- 집합 결과에 오류가 생기기 때문이다.
### 3. 숫자형이면서 인덱스 액세스 조건으로도 사용 가능한 컬럼에 대한 옵션 조건 처리는 LIKE방식을 사용해선 안된다.
```sql
SELECT * FROM 거래 WHERE 거래일자 = :trd_t and 고객ID LIKE :cust_id || '%'
```
이 경우 고객 ID는 문자열로 형변환이 발생한다.  
자동형변환이 발생하면 Full Scan을 하게 된다. (컬럼 가공시 인덱스가 안타짐)  
### 4. LIKE를 옵션 조건에 사용할 때는 컬럼 값 길이가 고정적이어야한다.
'김훈', '김훈남'이라는 고객명이 입력되었다고 가정해 보았을 때  
김훈을 찾기 위해선 김훈남까지 조회되야 한다.  
아래 경우와 같다.
```sql
where 고객명 like :cust_nm || '%'
```
따라서 컬럼 값 길이가 가변적인 경우 변구 값 길이가 같은 레코드만 조회되도록 아래와 같은 조건절을 추가해야한다.  
```sql
where 고객명 like :cust_nm || '%' AND length(고객명) = length(nvl(:cust_nm, 고객명))
```
## UNION ALL 활용
- :cust_id 변수에 값을 입력했는지에 따라 위아래 SQL중 어느 하나만 실행되게 하는 방식
```sql
SELECT * FROM 거래
WHERE :cust_id is NULL
and 거래일자 between :dt1 and :dt2
UNION ALL 
SELECT * FROM 거래
WHERE :cust_id is not NULL
and  고객ID = :cust_id
and 거래일자 between :dt1 and :Dt2
```
:cust_id 변수에 값을 입력하지 않으면 위쪽 브랜치에서 거래일자가 선두인 인덱스를 사용하고  
변수에 값을 입력하면 아래쪽 브랜치에서 고객ID + 거래일자 인덱스를 사용한다.  
이 방법을 사용하면 값을 입력하든 안하든 각 상황에서의 최적의 방법을 선택할 수 있다.  
-> 단점: SQL 코딩량이 길어짐  
## NVL/DECODE 함수 활용
NVL, DECODE 함수에 값을 넣어서 사용할 수 있는 방법도 있는데.  
어떤 컬럼을 함수 인자로 사용(인덱스 컬럼을 가공) 했는데도 인덱스를 사용할 수 있는것은  
OR Expansion 쿼리 변환이 일어났기 때문이다.  
앞서 살펴본 UNION ALL 방식으로 옵티마이저가 쿼리를 변환한 것이다.  
만약 옵티마이저가 작동하지 않는다면 NVL, DECODE 함수를 사용하는 패턴도 인덱스 액세스 조건으로 사용이 불가능하다.  
이 기능은 UNION ALL 보다 단순하면서도 UNION ALL과 같은 성능을 낸다.  
단점은 앞서 설명한 LIKE 패턴처럼 NULL허용 컬럼에 사용할 수 없다는데 있다.  
조건절 변수에 NULL을 입력하면 값이 NULL인 레코드가 결과 집합에 누락되기 떄문이다.  
### NVL/DECODE를 여러번 사용하는 경우
여러번 사용하는 경우 가장 변별력이 좋은 컬럼기준으로 한번만 OR Expansion이 일어난다.  
OR Expansion에 선택되지 않으면 인덱스 구성 컬럼이어도 모두 필터 조건으로 처리된다.  
NVL/DECODE 함수의 장점에도 불구하고 모든 옵션 조건을 이 방식으로 처리할 수 없는 이유가 이것이다.  
## 함수호출부하 해소를 위한 인덱스 구성
### PL/SQL 함수의 성능적 특성
- PL/SQL의 사용자 정의 함수는 개발자들이 일반적으로 생각하는것보다 훨씬 느리다.  
### 느린이유
1. VM위에서 도는 인터프리터 언어
2. 호출 시마다 컨텍스트 스위칭 발생
3. 내장 sql에 대한 Recursive Call 발생
- PL/SQL도 인터프리터 언어이기 때문에 NATIVE 코드로 완전 컴파일된 빌트인 함수에 비해 많이 느리다.  
- PL/SQL 함수는 실행시 매번 sql실행 엔진과 PL/SQL 가상머신 사이에 컨텍스트 스위칭이 일어난다.  
- 가장 성능 저하를 발생시키는 요소는 Recursive Call
```sql
SELECT 회원번호, 회원명, GET_ADDR(우편번호) from 회원
```
위에서 회원을 100만건 조회한다고 가정했을 때 GET_ADDR()도 100만번 호출되는데 GET_ADDR()에 SQL이 내장되어있으면  
그 SQL도 100만번 실행한다.  
대개 PL/SQL 함수에는 SQL이 내장돼 있으므로 일반적으로 인터프리팅, 컨텍스트 스위칭 보다 Recursive Call 부하가 가장 크다.  
PL/SQL 함수를 쓰지 않고 조인문으로 처리하면 성능차이가 매우 커진다.  
하지만 PL/SQL 함수 내부 로직이 복잡하면 그대로 쓸 수밖에 없는데 그럴 때 함수 호출 횟수를 줄이는 여러가지 방법이 있다.  
그중 하나가 **액세스 조건을 고려한 인덱스 구성**이다.
### 효과적인 인덱스 구성을 통한 함수호출 최소화
만약 사용자 정의 함수가 포함된 쿼리에 Table Full Scan방식으로 읽으면 테이블 건수만큼 실행된다.  
하지만 그 함수를 조건절에 넣으면 조건에 부합하는 횟수만큼만 호출된다.  
### 예시
인덱스 3개를 만들어보자  
- create index 회원_X01 on 회원(생년);
- create index 회원_X02 on 회원(생년, 생월일, 암호화된_전화번호);
- create index 회원_X03 on 회원(생년, 암호화된_전화번호);  
1. 첫번째 인덱스의 경우 암호화된_전화번호 조건절을 테이블 액세스 단계에서 필터링한다. 즉 생년 = '1987'조건을 만족하는 건수만큼 수행된다.  
```sql
where 생년 = '1987' and 암호화된_전화번호=encryption(:phone_no)
```
2. 두번째 인덱스의 경우 선행컬럼(생월일)이 조건절에 없는 경우 인덱스 필터 조건으로 들어가게 되는데 인덱스 스캔 횟수만큼 호출된다.  
```sql
where 생년 = '1987' and 암호화된_전화번호=encryption(:phone_no)
```
3. 마지막 인덱스의 경우 암호화된_전화번호를 조건절에 넣을 경우 인덱스 액세스 조건으로 사용되기 때문에 한번만 호출된다.  
```sql
where 생년 = '1987' and 암호화된_전화번호=encryption(:phone_no)
```
# 인덱스 설계
인덱스 추가는 시스템에 부하를 주고 인덱스 변경은 운영 리스크가 크다.  
**시스템 개발 단계**에서 인덱스를 최적으로 설계하는 일이 무엇보다 중요한 이유다.  
## 인덱스를 많이 생성하면 아래와 같은 문제가 생긴다.
- DML 성능 저하 (TPS 저하)
- 데이터베이스 사이즈 증가 (디스크 공간 낭비)
- 데이터베이스 관리 및 운영 비용 상승  
꼭 필요하지 않은 인덱스를 많이 만들면 디스크 공간을 낭비하고, 데이터베이스 사이즈가 커지는 만큼 백업, 복제 재구성 등을 위한  
운영 비용도 증가한다.  
### DML 성능 저하
예를들어 한 테이블에 인덱스가 6개 달려있으면 데이터 삽입시 6개의 인덱스에도 값을 넣어줘야 한다.  
테이블과 달리 인덱스는 정렬상태를 유지해야하므로 수직적탐색을 통해 입력할 블록부터 찾는다.  
찾은 블록에 여유공간이 없으면 Index Split도 발생한다.  
데이터를 삭제할때도 마찬가지이다.  
## 인덱스 설계시 가장 중요한 두가지 기준 (중요)
1. 조건절에 항상 사용하거나 자주 사용하는 컬럼을 선정한다.
2. 등치'=' 조건으로 자주 조회하는 컬럼을 앞쪽에 둔다.  
> 이것은 인덱스 스캔 효율성 판단기준이다.  
## 그 외 고려해야할 판단기준
- *수행 빈도
- 업무상 중요도
- 클러스터링 팩터
- 데이터량
- DML 부하 (기존 인덱스 개수, 초당 DML 발생량, 자주 갱신하는 컬럼 포함 여부 등)
- 저장 공간
- 인덱스 관리 비용 등